{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CityScape_Image_Segmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8WavclxY7ec"
      },
      "source": [
        "# Cityscape Image Segmentation without Keras!\n",
        "\n",
        "In this notebook, we will use the UNet image segmentation model to detect roads in the images of the Cityscape dataset.\n",
        "\n",
        "![UNet model](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
        "\n",
        "[Source](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoO-GqyEZQi-"
      },
      "source": [
        "\n",
        "## 1) **Importing the packages**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM2zzpbPc5vR"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image , ImageOps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1OyxrUsZ0Yd"
      },
      "source": [
        "\n",
        "## **2) Downloading the Cityscape Dataset**\n",
        "\n",
        "We will download the subset of the original dataset from Kaggle.com. It's [Cityscapes Image Pairs](https://www.kaggle.com/dansbecker/cityscapes-image-pairs) by [DanB](https://www.kaggle.com/dansbecker). I have hosted a bit modified version on my repo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhO_s8FHbKV"
      },
      "source": [
        "\n",
        "!wget https://github.com/shubham0204/Dataset_Archives/blob/master/cityscape_images.zip?raw=true -O cityscape_images.zip\n",
        "!unzip cityscape_images.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P43MGQhkCHcg"
      },
      "source": [
        "\n",
        "## **3) Processing the images.**\n",
        "\n",
        "Here, we will split the composite image into two parts, the one which contains the mask and second which is the actual image.\n",
        "\n",
        "- The class \"road\" in the mask have a colour of RGB value `( 128 , 63 , 127 )`. We will binarize the image.\n",
        "- The pixels who have a RGB value of `( 128 , 63 , 127 )` will be assigned a new value of 1. Rest all the pixels will have a new value of 0.\n",
        "- Hence the image shape changes from `( 128 , 128 , 3 )` to `( 128 , 128 , 1 )`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSFjJkwcpNk"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = list()\n",
        "y = list()\n",
        "\n",
        "#@markdown > The number of images to load from the dataset. By default 400 images are loaded.\n",
        "num_images = 400 #@param {type: \"number\" }\n",
        "\n",
        "image_dir = 'cityscape_images/images'\n",
        "image_filenames = os.listdir( image_dir )\n",
        "for filename in image_filenames[ 0 : 100 ]:\n",
        "\timage = Image \\\n",
        "\t\t.open(os.path.join( image_dir, filename))\n",
        "\tx.append( np.asarray( ImageOps.crop( image , ( 0 , 0 , 256 , 0 ) ).resize( ( 128, 128 )) ) )\n",
        "\ty.append(np.asarray( ImageOps.crop(image, (256, 0, 0, 0)).resize( ( 128 , 128 ) ) ))\n",
        "\n",
        "x = np.array( x ) / 255\n",
        "y = np.array( y )\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(np.array(x), np.array(y),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size=0.4)\n",
        "\n",
        "def binarize( pixel ):\n",
        "    if np.array_equal( pixel , [ 128 , 63 , 127 ]):\n",
        "        return np.array( [ 1 ] )\n",
        "    else :\n",
        "        return np.array( [ 0 ] )\n",
        "\n",
        "train_labels = np.apply_along_axis( binarize , axis=3 , arr=train_labels ) \n",
        "test_labels = np.apply_along_axis( binarize , axis=3 , arr=test_labels ) \n",
        "\n",
        "#@markdown > The batch size for the dataset.\n",
        "batch_size = 5  #@param {type: \"number\"}\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices( ( train_features , train_labels ) )\n",
        "train_dataset = train_dataset.shuffle( 1024 ).batch( batch_size )\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices( ( test_features , test_labels ) )\n",
        "test_dataset = test_dataset.shuffle( 1024 ).batch( batch_size )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvqjhexUIWYG"
      },
      "source": [
        "\n",
        "## **4) Defining the operations**\n",
        "\n",
        "We will define methods for four operations:\n",
        "\n",
        "1. `conv2d_down`: Regular Convolution along with Leaky ReLU activation.\n",
        "2. `maxpool_down`: Max Pooling operation with valid padding.\n",
        "3. `conv2d_up`: Transposed convolution for upsampling the image.\n",
        "4. `maxpool_up`: Upsampling the input like the `UpSampling2D` Keras layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXwbsMFzRxW6"
      },
      "source": [
        "\n",
        "#@markdown > ReLU slope for `tf.nn.leaky_relu`\n",
        "relu_alpha = 0.2  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown > Dropout rate for `tf.nn.dropout`\n",
        "dropout_rate = 0.5  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown > The padding for the convolution layers.\n",
        "padding = 'SAME' #@param [ 'SAME' , 'VALID' ]\n",
        "\n",
        "def conv2d_down( inputs , filters , stride_size ):\n",
        "    #print( 'conv2d down' )\n",
        "    out = tf.nn.conv2d( inputs , filters , strides=stride_size , padding=padding ) \n",
        "    return tf.nn.leaky_relu( out , alpha=0.2 ) \n",
        "\n",
        "def maxpool_down( inputs , pool_size , stride_size ):\n",
        "    #print( 'maxpool down' )\n",
        "    return tf.nn.max_pool( inputs , ksize=pool_size , padding='VALID' , strides=stride_size )\n",
        "\n",
        "def conv2d_up( inputs , filters , stride_size , output_shape ):\n",
        "    #print( 'conv2d up' )\n",
        "    out = tf.nn.conv2d_transpose( inputs , filters , output_shape=output_shape , strides=stride_size , padding=padding ) \n",
        "    return tf.nn.leaky_relu( out , alpha=0.2 ) \n",
        "\n",
        "def maxpool_up( inputs , size ):\n",
        "    #print( 'maxpool up' )\n",
        "    in_dimen = tf.shape( inputs )[ 1 ]\n",
        "    out_dimen = tf.cast( tf.round( in_dimen * size ) , dtype=tf.int32 ) \n",
        "    return tf.image.resize( inputs , [ out_dimen , out_dimen ] , method='nearest' ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6nx0wc8I0QW"
      },
      "source": [
        "\n",
        "## **5) Initializing the weights**\n",
        "\n",
        "Initializing the weights for our UNet model with Glorot Uniform initializer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyWrGANLQoFc"
      },
      "source": [
        "\n",
        "initializer = tf.initializers.glorot_uniform()\n",
        "def get_weight( shape , name ):\n",
        "    return tf.Variable( initializer( shape ) , name=name , trainable=True )\n",
        "\n",
        "shapes = [\n",
        "    [ 3 , 3 , 3 , 16 ] , \n",
        "    [ 3 , 3 , 16 , 16 ] , \n",
        "\n",
        "    [ 3 , 3 , 16 , 32 ] , \n",
        "    [ 3 , 3 , 32 , 32 ] ,\n",
        "\n",
        "    [ 3 , 3 , 32 , 64 ] , \n",
        "    [ 3 , 3 , 64 , 64 ] ,\n",
        "\n",
        "    [ 3 , 3 , 64 , 128 ] , \n",
        "    [ 3 , 3 , 128 , 128 ] ,\n",
        "\n",
        "    [ 3 , 3 , 128 , 256 ] , \n",
        "    [ 3 , 3 , 256 , 256 ] ,\n",
        "\n",
        "    [ 3 , 3 , 128 , 384 ],\n",
        "    [ 3 , 3 , 128 , 128 ],\n",
        "\n",
        "    [ 3 , 3 , 64 , 192 ],\n",
        "    [ 3 , 3 , 64 , 64 ],\n",
        "\n",
        "    [ 3 , 3 , 32 , 96 ],\n",
        "    [ 3 , 3 , 32 , 32 ],\n",
        "\n",
        "    [ 3 , 3 , 16 , 48 ],\n",
        "    [ 3 , 3 , 16 , 16 ],\n",
        "\n",
        "    [ 1 , 1 , 16 , 1 ],\n",
        "]\n",
        "\n",
        "weights = []\n",
        "for i in range( len( shapes ) ):\n",
        "    weights.append( get_weight( shapes[ i ] , 'weight{}'.format( i ) ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53LX5eVzLB5P"
      },
      "source": [
        "\n",
        "## **6) Assembling the model**\n",
        "\n",
        "We will put together all the ops to create our final UNet model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3w4D1V0SkZ8"
      },
      "source": [
        "\n",
        "def model( x ) :\n",
        "    batch_size = tf.shape( x )[0]\n",
        "    x = tf.cast( x , dtype=tf.float32 )\n",
        "    c1 = conv2d_down( x , weights[ 0 ] , stride_size=1 ) \n",
        "    c1 = conv2d_down( c1 , weights[ 1 ] , stride_size=1 ) \n",
        "    p1 = maxpool_down( c1 , pool_size=2 , stride_size=2 )\n",
        "    \n",
        "    c2 = conv2d_down( p1 , weights[ 2 ] , stride_size=1 )\n",
        "    c2 = conv2d_down( c2 , weights[ 3 ] , stride_size=1 ) \n",
        "    p2 = maxpool_down( c2 , pool_size=2 , stride_size=2 )\n",
        "    \n",
        "    c3 = conv2d_down( p2 , weights[ 4 ] , stride_size=1 ) \n",
        "    c3 = conv2d_down( c3 , weights[ 5 ] , stride_size=1 ) \n",
        "    p3 = maxpool_down( c3 , pool_size=2 , stride_size=2 )\n",
        "    \n",
        "    c4 = conv2d_down( p3 , weights[ 6 ] , stride_size=1 )\n",
        "    c4 = conv2d_down( c4 , weights[ 7 ] , stride_size=1 )\n",
        "    p4 = maxpool_down( c4 , pool_size=2 , stride_size=2 )\n",
        "\n",
        "    c5 = conv2d_down( p4 , weights[ 8 ] , stride_size=1 )\n",
        "    c5 = conv2d_down( c5 , weights[ 9 ] , stride_size=1 ) \n",
        "        \n",
        "    p5 = maxpool_up( c5 , 2 )\n",
        "    concat_1 = tf.concat( [ p5 , c4 ] , axis=-1 ) \n",
        "    c6 = conv2d_up( concat_1 , weights[ 10 ] , stride_size=1 , output_shape=[ batch_size , 16 , 16 , 128 ] )\n",
        "    c6 = conv2d_up( c6 , weights[ 11 ] , stride_size=1 , output_shape=[ batch_size , 16 , 16 , 128 ] )  \n",
        "\n",
        "    p6 = maxpool_up( c6 , 2 )\n",
        "    concat_2 = tf.concat( [ p6 , c3 ] , axis=-1 ) \n",
        "    c7 = conv2d_up( concat_2 , weights[ 12 ] , stride_size=1 , output_shape=[ batch_size , 32 , 32 , 64 ] )\n",
        "    c7 = conv2d_up( c7 , weights[ 13 ] , stride_size=1 , output_shape=[ batch_size , 32 , 32 , 64 ] )  \n",
        "\n",
        "    p7 = maxpool_up( c7 , 2 )\n",
        "    concat_3 = tf.concat( [ p7 , c2 ] , axis=-1 ) \n",
        "    c8 = conv2d_up( concat_3 , weights[ 14 ] , stride_size=1 , output_shape=[ batch_size , 64 , 64 , 32 ] )\n",
        "    c8 = conv2d_up( c8 , weights[ 15 ] , stride_size=1 , output_shape=[ batch_size , 64 , 64 , 32 ] )   \n",
        "\n",
        "    p8 = maxpool_up( c8 , 2 )\n",
        "    concat_4 = tf.concat( [ p8 , c1 ] , axis=-1 ) \n",
        "    c9 = conv2d_up( concat_4 , weights[ 16 ] , stride_size=1 , output_shape=[ batch_size , 128 , 128 , 16 ] )\n",
        "    c9 = conv2d_up( c9 , weights[ 17 ] , stride_size=1 , output_shape=[ batch_size , 128 , 128 , 16 ] )   \n",
        "\n",
        "    output = tf.nn.conv2d( c9 , weights[ 18 ] , strides=[ 1 , 1 , 1 , 1 ] , padding=padding ) \n",
        "    outputs = tf.nn.sigmoid( output ) \n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDxJdWCsLOEF"
      },
      "source": [
        "\n",
        "## **7) Optimization and Training**\n",
        "\n",
        "We use `tf.losses.binary_crossentropy` as our loss function and the `tf.optimizers.Adam` optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEVrQaC5Vdbk"
      },
      "source": [
        "\n",
        "def loss( pred , target ):\n",
        "    return tf.losses.binary_crossentropy( target , pred )\n",
        "\n",
        "#@markdown > The learning rate used during optimization using Adam.\n",
        "learning_rate = \"0.001\"  #@param [ \"0.1\" , \"0.001\" , \"0.0001\" , \"0.05\" ]\n",
        "optimizer = tf.optimizers.Adam( learning_rate=float( learning_rate ) )\n",
        "\n",
        "def train( model, inputs , outputs ):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = loss( model( inputs ), outputs)\n",
        "    grads = tape.gradient( current_loss , weights )\n",
        "    optimizer.apply_gradients( zip( grads , weights ) )\n",
        "    return tf.reduce_mean( current_loss )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMW_KVbFLicF"
      },
      "source": [
        "We start training the model for a specific number of epochs and print the loss. We write the loss value with `tf.summary.scalar` so that we can visualize it with [TensorBoard](https://www.tensorflow.org/tensorboard/get_started)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x7dpw9XlKOI"
      },
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmt3fVSooMLm"
      },
      "source": [
        "  \n",
        "import datetime\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer( logdir + \"/metrics\")\n",
        "file_writer.set_as_default()\n",
        "\n",
        "#@markdown > Number of epochs for training the model\n",
        "num_epochs = 25  #@param {type: \"number\"}\n",
        "\n",
        "for e in range( num_epochs ):\n",
        "    print( 'Epoch {} out of {} {}'.format( e + 1 , num_epochs , '--' * 50 ) )\n",
        "    for features in train_dataset:\n",
        "        image , label = features\n",
        "        summ_loss = train( model , image , label )\n",
        "        tf.summary.scalar('loss', data=summ_loss, step=e )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_is1h0uZL4w0"
      },
      "source": [
        "\n",
        "tf.saved_model.save( model , 'module_no_signatures') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WwmwQHJLwUt"
      },
      "source": [
        "Additionally, we can plot the image and its corresponding mask to view the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ5cm5gF3feo"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_image = test_features[0:1]\n",
        "pred = model( input_image ).numpy()\n",
        "image = np.zeros( ( 128 , 128 , 3 ) )\n",
        "for x in range( 128 ):\n",
        "    for y in range( 128 ):\n",
        "        if pred[ 0 , x , y ] > 0.5:\n",
        "            image[ x , y ] = [ 255 , 255 , 255 ]\n",
        "        else:\n",
        "            image[ x , y ] = [ 0, 0, 0]\n",
        "\n",
        "def show_images(images: list):\n",
        "    n = len(images)\n",
        "    f = plt.figure()\n",
        "    for i in range(n):\n",
        "        f.add_subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i] , interpolation='none' )\n",
        "    plt.show()\n",
        "\n",
        "show_images( [ test_features[0] , image ] )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}